{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from sklearn.cluster import KMeans\n",
    "import hmmlearn.hmm\n",
    "\n",
    "def get_mfcc(file_path):\n",
    "    y, sr = librosa.load(file_path) # read .wav file\n",
    "    hop_length = math.floor(sr*0.010) # 10ms hop\n",
    "    win_length = math.floor(sr*0.025) # 25ms frame\n",
    "    # mfcc is 12 x T matrix\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y, sr, n_mfcc=12, n_fft=1024,\n",
    "        hop_length=hop_length, win_length=win_length)\n",
    "    # substract mean from mfcc --> normalize mfcc\n",
    "    mfcc = mfcc - np.mean(mfcc, axis=1).reshape((-1,1)) \n",
    "    # delta feature 1st order and 2nd order\n",
    "    delta1 = librosa.feature.delta(mfcc, order=1)\n",
    "    delta2 = librosa.feature.delta(mfcc, order=2)\n",
    "    # X is 36 x T\n",
    "    X = np.concatenate([mfcc, delta1, delta2], axis=0) # O^r\n",
    "    # return T x 36 (transpose of X)\n",
    "    return X.T # hmmlearn use T x N matrix\n",
    "\n",
    "def get_class_data(data_dir):\n",
    "    files = os.listdir(data_dir)\n",
    "    mfcc = [get_mfcc(os.path.join(data_dir,f)) for f in files if f.endswith(\".wav\")]\n",
    "    print('data_dir: ', data_dir)\n",
    "    print(f'mfcc.shape: {np.array(mfcc).shape}')\n",
    "    return mfcc\n",
    "\n",
    "def clustering(X, n_clusters=10):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=50, random_state=0, verbose=0)\n",
    "    kmeans.fit(X)\n",
    "    print(\"centers\", kmeans.cluster_centers_.shape)\n",
    "    return kmeans  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"cothe\", \"khong\", \"nguoi\", \"toi\", \"va\" , \"test_cothe\" , \"test_khong\" , \"test_nguoi\", \"test_toi\", \"test_va\" ]\n",
    "dataset = {}\n",
    "for cname in class_names:\n",
    "    print(f\"Load {cname} dataset\")\n",
    "    dataset[cname] = get_class_data(os.path.join(\"data\", cname))\n",
    " \n",
    "# Get all vectors in the datasets\n",
    "all_vectors = np.concatenate([np.concatenate(v, axis=0) for k, v in dataset.items()], axis=0)\n",
    "print(\"vectors\", all_vectors.shape)\n",
    "# Run K-Means algorithm to get clusters\n",
    "kmeans = clustering(all_vectors)\n",
    "print(\"centers\", kmeans.cluster_centers_.shape)    \n",
    "\n",
    "models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "original_dataset = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#từ\n",
    "original_dataset['cothe'] = dataset['cothe'].copy()\n",
    "cname = 'cothe'\n",
    "class_vectors = dataset[cname]\n",
    "# convert all vectors to the cluster index\n",
    "# dataset['one'] = [O^1, ... O^R] , O^r: the r-th recorded wav file \n",
    "# O^r = (c1, c2, ... ct, ... cT) , c_i: the i-th frame in the r-th observation ( or the r-th wav file )\n",
    "# O^r size T x 1\n",
    "dataset[cname] = list([kmeans.predict(v).reshape(-1,1) for v in original_dataset[cname]])\n",
    "\n",
    "\n",
    "hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "    n_components=13, random_state=0, n_iter=1000, verbose=True,\n",
    "    params='te',\n",
    "    init_params='e'\n",
    ")\n",
    "hmm.startprob_=np.array([0.6,0.3,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0])\n",
    "hmm.transmat_=np.array([\n",
    "    [0.6,0.3,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "    [0.0,0.6,0.3,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "    [0.0,0.0,0.6,0.3,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "    [0.0,0.0,0.0,0.6,0.3,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "    [0.0,0.0,0.0,0.0,0.6,0.3,0.1,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "    [0.0,0.0,0.0,0.0,0.0,0.6,0.3,0.1,0.0,0.0,0.0,0.0,0.0],\n",
    "    [0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.3,0.1,0.0,0.0,0.0,0.0],\n",
    "    [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.3,0.1,0.0,0.0,0.0],\n",
    "    [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.3,0.1,0.0,0.0],\n",
    "    [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.3,0.1,0.0],\n",
    "    [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.3,0.1],\n",
    "    [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3],\n",
    "    [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0],\n",
    "])\n",
    "if cname[:4] != 'test':\n",
    "    X = np.concatenate(dataset[cname])\n",
    "    lengths = list([len(x) for x in dataset[cname]])\n",
    "    print(\"training class\", cname)\n",
    "    print(X.shape, lengths, len(lengths))\n",
    "    hmm.fit(X, lengths=lengths)\n",
    "    models[cname] = hmm\n",
    "#dataset['test_cothe'] = list([kmeans.predict(v).reshape(-1,1) for v in dataset['test_cothe']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#từ\n",
    "original_dataset['toi'] = dataset['toi'].copy()\n",
    "cname = 'toi'\n",
    "class_vectors = dataset[cname]\n",
    "# convert all vectors to the cluster index\n",
    "# dataset['one'] = [O^1, ... O^R] , O^r: the r-th recorded wav file \n",
    "# O^r = (c1, c2, ... ct, ... cT) , c_i: the i-th frame in the r-th observation ( or the r-th wav file )\n",
    "# O^r size T x 1\n",
    "\n",
    "dataset[cname] = list([kmeans.predict(v).reshape(-1,1) for v in original_dataset[cname]])\n",
    "\n",
    "\n",
    "hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "    n_components= 8, random_state=0, n_iter=1100, verbose=True,\n",
    "    params='te',\n",
    "    init_params='e'\n",
    ")\n",
    "hmm.startprob_ = np.array([0.6,0.3,0.1,0.0,0.0,0.0,0.0,0.0,])\n",
    "hmm.transmat_ = np.array([\n",
    "        [0.5,0.3,0.2,0.0,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.5,0.3,0.2,0.0,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.5,0.3,0.2,0.0,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.5,0.3,0.2,0.0,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.5,0.3,0.2,0.0],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.5,0.3,0.2],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.4],\n",
    "        [0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0],       \n",
    "    ])\n",
    "\n",
    "if cname[:4] != 'test':\n",
    "    X = np.concatenate(dataset[cname])\n",
    "    lengths = list([len(x) for x in dataset[cname]])\n",
    "    print(\"training class\", cname)\n",
    "    print(X.shape, lengths, len(lengths))\n",
    "    hmm.fit(X, lengths=lengths)\n",
    "    models[cname] = hmm\n",
    "#dataset['test_toi'] = list([kmeans.predict(v).reshape(-1,1) for v in dataset['test_toi']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#từ\n",
    "original_dataset['khong'] = dataset['khong'].copy()\n",
    "cname = 'khong'\n",
    "class_vectors = dataset[cname]\n",
    "# convert all vectors to the cluster index\n",
    "# dataset['one'] = [O^1, ... O^R] , O^r: the r-th recorded wav file \n",
    "# O^r = (c1, c2, ... ct, ... cT) , c_i: the i-th frame in the r-th observation ( or the r-th wav file )\n",
    "# O^r size T x 1\n",
    "dataset[cname] = list([kmeans.predict(v).reshape(-1,1) for v in original_dataset[cname]])\n",
    "\n",
    "\n",
    "hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "    n_components=13, random_state=0, n_iter=1000, verbose=True,\n",
    "    params='te',\n",
    "    init_params='e'\n",
    ")\n",
    "hmm.startprob_=np.array([0.6,0.3,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0])\n",
    "hmm.transmat_=np.array([\n",
    "    [0.6,0.3,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "    [0.0,0.6,0.3,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "    [0.0,0.0,0.6,0.3,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "    [0.0,0.0,0.0,0.6,0.3,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "    [0.0,0.0,0.0,0.0,0.6,0.3,0.1,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "    [0.0,0.0,0.0,0.0,0.0,0.6,0.3,0.1,0.0,0.0,0.0,0.0,0.0],\n",
    "    [0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.3,0.1,0.0,0.0,0.0,0.0],\n",
    "    [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.3,0.1,0.0,0.0,0.0],\n",
    "    [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.3,0.1,0.0,0.0],\n",
    "    [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.3,0.1,0.0],\n",
    "    [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.3,0.1],\n",
    "    [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3],\n",
    "    [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0],\n",
    "])\n",
    "if cname[:4] != 'test':\n",
    "    X = np.concatenate(dataset[cname])\n",
    "    lengths = list([len(x) for x in dataset[cname]])\n",
    "    print(\"training class\", cname)\n",
    "    print(X.shape, lengths, len(lengths))\n",
    "    hmm.fit(X, lengths=lengths)\n",
    "    models[cname] = hmm\n",
    "#dataset['test_khong'] = list([kmeans.predict(v).reshape(-1,1) for v in dataset['test_khong']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#từ\n",
    "original_dataset['nguoi'] = dataset['nguoi'].copy()\n",
    "cname = 'nguoi'\n",
    "class_vectors = dataset[cname]\n",
    "# convert all vectors to the cluster index\n",
    "# dataset['one'] = [O^1, ... O^R] , O^r: the r-th recorded wav file \n",
    "# O^r = (c1, c2, ... ct, ... cT) , c_i: the i-th frame in the r-th observation ( or the r-th wav file )\n",
    "# O^r size T x 1\n",
    "dataset[cname] = list([kmeans.predict(v).reshape(-1,1) for v in original_dataset[cname]])\n",
    "\n",
    "\n",
    "hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "    n_components=13, random_state=0, n_iter=1000, verbose=True,\n",
    "    params='te',\n",
    "    init_params='e'\n",
    ")\n",
    "hmm.startprob_=np.array([0.6,0.3,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0])\n",
    "hmm.transmat_=np.array([\n",
    "    [0.6,0.3,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "    [0.0,0.6,0.3,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "    [0.0,0.0,0.6,0.3,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "    [0.0,0.0,0.0,0.6,0.3,0.1,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "    [0.0,0.0,0.0,0.0,0.6,0.3,0.1,0.0,0.0,0.0,0.0,0.0,0.0],\n",
    "    [0.0,0.0,0.0,0.0,0.0,0.6,0.3,0.1,0.0,0.0,0.0,0.0,0.0],\n",
    "    [0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.3,0.1,0.0,0.0,0.0,0.0],\n",
    "    [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.3,0.1,0.0,0.0,0.0],\n",
    "    [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.3,0.1,0.0,0.0],\n",
    "    [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.3,0.1,0.0],\n",
    "    [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.6,0.3,0.1],\n",
    "    [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7,0.3],\n",
    "    [0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0],\n",
    "])\n",
    "if cname[:4] != 'test':\n",
    "    X = np.concatenate(dataset[cname])\n",
    "    lengths = list([len(x) for x in dataset[cname]])\n",
    "    print(\"training class\", cname)\n",
    "    print(X.shape, lengths, len(lengths))\n",
    "    hmm.fit(X, lengths=lengths)\n",
    "    models[cname] = hmm\n",
    "#dataset['test_nguoi'] = list([kmeans.predict(v).reshape(-1,1) for v in dataset['test_nguoi']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#từ\n",
    "original_dataset['va'] = dataset['va'].copy()\n",
    "cname = 'va'\n",
    "class_vectors = dataset[cname]\n",
    "# convert all vectors to the cluster index\n",
    "# dataset['one'] = [O^1, ... O^R] , O^r: the r-th recorded wav file \n",
    "# O^r = (c1, c2, ... ct, ... cT) , c_i: the i-th frame in the r-th observation ( or the r-th wav file )\n",
    "# O^r size T x 1\n",
    "dataset[cname] = list([kmeans.predict(v).reshape(-1,1) for v in original_dataset[cname]])\n",
    "\n",
    "\n",
    "hmm = hmmlearn.hmm.MultinomialHMM(\n",
    "    n_components=5, random_state=0, n_iter=1000, verbose=True,\n",
    "    params='te',\n",
    "    init_params='e'\n",
    ")\n",
    "hmm.startprob_=np.array([0.7,0.2,0.1,0.0,0.0])\n",
    "hmm.transmat_=np.array([\n",
    "    [0.7,0.2,0.1,0.0,0.0],\n",
    "    [0.0,0.7,0.2,0.1,0.0],\n",
    "    [0.0,0.0,0.7,0.2,0.1],\n",
    "    [0.0,0.0,0.0,0.6,0.4],\n",
    "    [0.0,0.0,0.0,0.0,1.0],\n",
    "])\n",
    "if cname[:4] != 'test':\n",
    "    X = np.concatenate(dataset[cname])\n",
    "    lengths = list([len(x) for x in dataset[cname]])\n",
    "    print(\"training class\", cname)\n",
    "    print(X.shape, lengths, len(lengths))\n",
    "    hmm.fit(X, lengths=lengths)\n",
    "    models[cname] = hmm\n",
    "#dataset['test_va'] = list([kmeans.predict(v).reshape(-1,1) for v in dataset['test_va']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['test_va'] = list([kmeans.predict(v).reshape(-1,1) for v in dataset['test_va']])\n",
    "\n",
    "dataset['test_cothe'] = list([kmeans.predict(v).reshape(-1,1) for v in dataset['test_cothe']])\n",
    "dataset['test_toi'] = list([kmeans.predict(v).reshape(-1,1) for v in dataset['test_toi']])\n",
    "dataset['test_khong'] = list([kmeans.predict(v).reshape(-1,1) for v in dataset['test_khong']])\n",
    "dataset['test_nguoi'] = list([kmeans.predict(v).reshape(-1,1) for v in dataset['test_nguoi']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing\")\n",
    "for true_cname in class_names:\n",
    "    for O in dataset[true_cname]:\n",
    "        score = {cname : model.score(O, [len(O)]) for cname, model in models.items() if cname[:4] != 'test' }\n",
    "        print(true_cname, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "print(\"Testing\")\n",
    "\n",
    "class_names = [\"test_cothe\",\"test_toi\", \"test_khong\", \"test_nguoi\", \"test_va\"]\n",
    "for true_cname in class_names:\n",
    "    index = 0\n",
    "    count = 0;\n",
    "    total = 0;\n",
    "    print(\"-----------------------\")\n",
    "    for O in dataset[true_cname]:\n",
    "        index+=1\n",
    "        total+=1\n",
    "        pred = max(score.items(), key=operator.itemgetter(1))[0]\n",
    "        if(true_cname[5:] == pred): count+=1\n",
    "        score = {cname : model.score(O, [len(O)]) for cname, model in models.items() if cname[:4] != 'test' }\n",
    "        print(true_cname, pred, index)\n",
    "    print(count / total * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import queue\n",
    "import math\n",
    "import threading\n",
    "from pynput import keyboard\n",
    "\n",
    "from python_speech_features import mfcc\n",
    "from sklearn.cluster import KMeans\n",
    "import hmmlearn.hmm\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "\n",
    "import librosa\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "\n",
    "CLASS_LABELS = {\"cothe\", \"toi\", \"khong\", \"nguoi\", \"va\"}\n",
    "\n",
    "# Controls\n",
    "STOP_RECORD_CMD = \"/s\"\n",
    "RECORD_CMD = \"/r\"\n",
    "\n",
    "inputQueue = queue.Queue()\n",
    "\n",
    "def read_kb_input(inputQueue):\n",
    "    while True:\n",
    "        input_str = input()\n",
    "        inputQueue.put(input_str)\n",
    "\n",
    "# Indexing functions\n",
    "def writeIndex(file, sentence, file_name):\n",
    "    file.write(file_name + \"\\n\")\n",
    "    file.write(sentence  + \"\\n\")\n",
    "\n",
    "# Recording functions\n",
    "SAMPLE_RATE = 22050\n",
    "CHANNELS = 2\n",
    "\n",
    "q = queue.Queue()\n",
    "\n",
    "def callback( indata, frames, time, status):\n",
    "    #This is called (from a separate thread) for each audio block.\n",
    "    if status:\n",
    "        print(status, file=sys.stderr)\n",
    "    q.put(indata.copy())\n",
    "\n",
    "def record(file_name):\n",
    "    try:\n",
    "        #Open a new soundfile and attempt recording\n",
    "        with sf.SoundFile(file_name, mode='x', samplerate=SAMPLE_RATE, channels=CHANNELS, subtype=\"PCM_24\") as file:\n",
    "            with sd.InputStream(samplerate=SAMPLE_RATE, device=sd.default.device, channels=CHANNELS, callback=callback):\n",
    "                print(\"Recording ... ('{}' to stop recording)\".format(STOP_RECORD_CMD))\n",
    "            \n",
    "                while True:\n",
    "                    file.write(q.get())\n",
    "\n",
    "                    if (inputQueue.qsize() > 0):\n",
    "                        input_str = inputQueue.get()\n",
    "                        if (input_str == STOP_RECORD_CMD):\n",
    "                            break\n",
    "\n",
    "                print(\"Saved to: {}\\n\".format(file_name))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "# Kmeans\n",
    "def clustering(X, n_clusters=10):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, n_init=50, random_state=0, verbose=0)\n",
    "    kmeans.fit(X)\n",
    "    return kmeans  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Models\\\\va.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-2dbd230fa2ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mCLASS_LABELS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Models\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Press any key to start recording\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Models\\\\va.pkl'"
     ]
    }
   ],
   "source": [
    "\n",
    "    models = {}\n",
    "    for label in CLASS_LABELS:\n",
    "        with open(os.path.join(\"Models\", label + \".pkl\"), \"rb\") as file: models[label] = pk.load(file)\n",
    "\n",
    "    input(\"Press any key to start recording\")\n",
    "\n",
    "    inputThread = threading.Thread(target=read_kb_input, args=(inputQueue,), daemon=True)\n",
    "    inputThread.start()\n",
    "\n",
    "    record(\"live_recording.wav\")\n",
    "\n",
    "    sound_mfcc = MFCC.get_mfcc(\"live_recording.wav\")\n",
    "\n",
    "    os.remove(\"live_recording.wav\")\n",
    "\n",
    "    kmeans = clustering(sound_mfcc)\n",
    "    sound_mfcc = kmeans.predict(sound_mfcc).reshape(-1,1)\n",
    "\n",
    "    evals = {cname : model.score(sound_mfcc, [len(sound_mfcc)]) for cname, model in models.items()}\n",
    "    cmax = max(evals.keys(), key=(lambda k: evals[k]))\n",
    "    print(evals)\n",
    "    print(\"Conclusion: \" + cmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
